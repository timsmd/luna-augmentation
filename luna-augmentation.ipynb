{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from settings import Settings\n",
    "from utils import *\n",
    "from data_processor import data_processor\n",
    "from augment_patient import augment_patient\n",
    "\n",
    "lungPatients, labels = load_data()\n",
    "\n",
    "size = Settings.size\n",
    "no_slices = Settings.no_slices\n",
    "\n",
    "imageData = []\n",
    "augData = []\n",
    "\n",
    "for num, patient in enumerate(lungPatients):\n",
    "    if num % 100 == 0:\n",
    "        print('Saved -', num)\n",
    "    try:\n",
    "        patient_data = data_processor(patient=patient, labels_df=labels, size=size, noslices=no_slices, visualize=False)\n",
    "        \n",
    "        if get_label(patient, labels) == 1:\n",
    "            augmented_data = []\n",
    "            for i in range(Settings.aug_counter):\n",
    "                augmented_data.append(augment_patient(patient=patient, labels_df=labels, iteration=i, size=size, noslices=no_slices, visualize=False))\n",
    "            for each in augmented_data:\n",
    "                augData.append(each['img_data'], each['label'], each['patient'])\n",
    "    \n",
    "        imageData.append([patient_data['img_data'], patient_data['label'], patient_data['patient']])\n",
    "    except KeyError as e:\n",
    "        print('Data is unlabeled')\n",
    "    except Exception as er:\n",
    "        print(er)\n",
    "\n",
    "        \n",
    "##Results are saved as numpy file\n",
    "np.save('imageDataNew-{}-{}-{}.npy'.format(size, size, no_slices), imageData)\n",
    "np.save('augmentedDataNew-{}-{}-{}.npy'.format(size, size, no_slices), augData)\n",
    "print(imageData.shape)\n",
    "print(augData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageData = np.load('imageDataNew-50-50-20.npy')\n",
    "trainingData = imageData[0:436]\n",
    "validationData = imageData[-100:]\n",
    "\n",
    "augData = np.load('augmentedDataNew-50-50-20.npy')\n",
    "trainingData.append(augData)\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "size = 50\n",
    "keep_rate = 0.8\n",
    "NoSlices = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def maxpooling3d(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def cnn(x):\n",
    "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
    "    convolution1 = tf.nn.relu(\n",
    "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
    "    convolution1 = maxpooling3d(convolution1)\n",
    "    convolution2 = tf.nn.relu(\n",
    "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
    "            tf.random_normal([64])))\n",
    "    convolution2 = maxpooling3d(convolution2)\n",
    "    convolution3 = tf.nn.relu(\n",
    "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
    "            tf.random_normal([128])))\n",
    "    convolution3 = maxpooling3d(convolution3)\n",
    "    convolution4 = tf.nn.relu(\n",
    "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
    "            tf.random_normal([256])))\n",
    "    convolution4 = maxpooling3d(convolution4)\n",
    "    convolution5 = tf.nn.relu(\n",
    "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
    "            tf.random_normal([512])))\n",
    "    convolution5 = maxpooling3d(convolution4)\n",
    "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
    "    fullyconnected = tf.nn.relu(\n",
    "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
    "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
    "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
    "    return output\n",
    "\n",
    "\n",
    "def network(x):\n",
    "    prediction = cnn(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    epochs = 10\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in trainingData:\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "           # if tf.argmax(prediction, 1) == 0:\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            print('Epoch', epoch + 1, 'completed out of', epochs, 'loss:', epoch_loss)\n",
    "            # print('Correct:',correct.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "            print('Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "        print('Final Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "        patients = []\n",
    "        actual = []\n",
    "        predicted = []\n",
    "\n",
    "        finalprediction = tf.argmax(prediction, 1)\n",
    "        actualprediction = tf.argmax(y, 1)\n",
    "        for i in range(len(validationData)):\n",
    "            patients.append(validationData[i][2])\n",
    "        for i in finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "            if(i==1):\n",
    "                predicted.append(\"Cancer\")\n",
    "            else:\n",
    "                predicted.append(\"No Cancer\")\n",
    "        for i in actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "            if(i==1):\n",
    "                actual.append(\"Cancer\")\n",
    "            else:\n",
    "                actual.append(\"No Cancer\")\n",
    "        for i in range(len(patients)):\n",
    "            print(\"Patient: \",patients[i])\n",
    "            print(\"Actual: \", actual[i])\n",
    "            print(\"Predcited: \", predicted[i])\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        y_actual = pd.Series(\n",
    "            (actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "            name='Actual')\n",
    "        y_predicted = pd.Series(\n",
    "            (finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "            name='Predicted')\n",
    "        df_confusion = pd.crosstab(y_actual, y_predicted)\n",
    "        print(df_confusion)\n",
    "\n",
    "        ## Function to plot confusion matrix\n",
    "        def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\\\n",
    "            \n",
    "            plt.matshow(df_confusion, cmap=cmap)  # imshow  \n",
    "            # plt.title(title)\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(df_confusion.columns))\n",
    "            plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "            plt.yticks(tick_marks, df_confusion.index)\n",
    "            # plt.tight_layout()\n",
    "            plt.ylabel(df_confusion.index.name)\n",
    "            plt.xlabel(df_confusion.columns.name)\n",
    "            plt.show()\n",
    "        plot_confusion_matrix(df_confusion)\n",
    "        # print(y_true,y_pred)\n",
    "        # print(confusion_matrix(y_true, y_pred))\n",
    "        # print(actualprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "        # print(finalprediction.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imageData = np.load('imageDataNew-50-50-20.npy')\n",
    "trainingData = imageData[0:800]\n",
    "testData = imageData[-1:]\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "size = 50\n",
    "keep_rate = 0.8\n",
    "NoSlices = 20\n",
    "\n",
    "\n",
    "def convolution3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def maxpooling3d(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def cnn(x):\n",
    "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
    "    convolution1 = tf.nn.relu(\n",
    "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
    "    convolution1 = maxpooling3d(convolution1)\n",
    "    convolution2 = tf.nn.relu(\n",
    "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
    "            tf.random_normal([64])))\n",
    "    convolution2 = maxpooling3d(convolution2)\n",
    "    convolution3 = tf.nn.relu(\n",
    "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
    "            tf.random_normal([128])))\n",
    "    convolution3 = maxpooling3d(convolution3)\n",
    "    convolution4 = tf.nn.relu(\n",
    "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
    "            tf.random_normal([256])))\n",
    "    convolution4 = maxpooling3d(convolution4)\n",
    "    convolution5 = tf.nn.relu(\n",
    "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
    "            tf.random_normal([512])))\n",
    "    convolution5 = maxpooling3d(convolution4)\n",
    "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
    "    fullyconnected = tf.nn.relu(\n",
    "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
    "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
    "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
    "    return output\n",
    "\n",
    "\n",
    "def network(x):\n",
    "    prediction = cnn(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    epochs = 10\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in trainingData:\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "        patients = []\n",
    "        actual = []\n",
    "        predicted = []\n",
    "\n",
    "        finalprediction = tf.argmax(prediction, 1)\n",
    "        actualprediction = tf.argmax(y, 1)\n",
    "        for i in range(len(testData)):\n",
    "            patients.append(testData[i][2])\n",
    "        for i in finalprediction.eval({x: [i[0] for i in testData], y: [i[1] for i in testData]}):\n",
    "            if(i==1):\n",
    "                predicted.append(\"Cancer\")\n",
    "            else:\n",
    "                predicted.append(\"No Cancer\")\n",
    "\n",
    "        for i in range(len(patients)):\n",
    "            print(\"Patient: \",patients[i])\n",
    "            print(\"Predcited: \", predicted[i])\n",
    "\n",
    "     \n",
    "network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
